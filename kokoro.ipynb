{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Kokoro TTS Alternative\n",
    "\n",
    "This notebook provides an alternative text-to-speech (TTS) implementation using the Kokoro library instead of OpenAI's TTS models used in the main project (`gutenberg_to_audio_gpt4o.ipynb`).\n",
    "\n",
    "## Purpose\n",
    "- This is NOT the main project workflow\n",
    "- Serves as an alternative TTS solution when OpenAI's TTS is not preferred\n",
    "- Uses the open-source Kokoro TTS library instead of OpenAI's API\n",
    "\n",
    "## Integration with Main Project\n",
    "This notebook is designed to work with the same file structure as the main project:\n",
    "- Uses the same book ID system\n",
    "- Processes text with similar chapter/section organization\n",
    "- Outputs files that can be used interchangeably with the main project\n",
    "\n",
    "## Requirements\n",
    "- Kokoro library (`pip install kokoro>=0.3.4`)\n",
    "- soundfile\n",
    "- espeak-ng (for phoneme processing)\n",
    "- pydub (for audio concatenation)\n",
    "\n",
    "## Usage\n",
    "1. Set the `BOOK_ID` variable to match your Project Gutenberg book\n",
    "2. Adjust chapter ranges with `CHAPTER`, `CHUNK`, `CHUNK_START`, and `CHUNK_END` variables\n",
    "3. Run cells sequentially to process the book with Kokoro TTS\n"
   ],
   "id": "704d0db380683956"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-24T01:34:36.091252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "BOOK_ID = 34167\n",
    "CHAPTER_START = 0\n",
    "CHAPTER_STOP = 99\n",
    "\n",
    "# Check if cleaned text files exist\n",
    "txt_dir = f\"books/{BOOK_ID}/txt\"\n",
    "if not os.path.exists(txt_dir):\n",
    "    raise FileNotFoundError(f\"Directory {txt_dir} not found. Please run the text cleaning process in gutenberg_to_audio_gpt4o.ipynb first.\")\n",
    "\n",
    "# Get all cleaned text files\n",
    "cleaned_files = sorted(glob.glob(f\"{txt_dir}/clean_text_*.txt\"))\n",
    "if not cleaned_files:\n",
    "    raise FileNotFoundError(f\"No cleaned text files found in {txt_dir}. Please run the text cleaning process in gutenberg_to_audio_gpt4o.ipynb first.\")\n",
    "\n",
    "print(f\"Found {len(cleaned_files)} cleaned text files.\")\n",
    "\n",
    "import os\n",
    "from kokoro import KPipeline\n",
    "from IPython.display import display, Audio\n",
    "import soundfile as sf\n",
    "\n",
    "pipeline = KPipeline(lang_code='a')\n",
    "\n",
    "\n",
    "def text_to_wav_kokoro(pipeline, text: str, book_id: str, chapter_id: int, section_id: int):\n",
    "    \"\"\"Convert text to speech using Kokoro TTS and save as a WAV file.\"\"\"\n",
    "    # Remove line breaks and whitespace from the beginning and end of the text\n",
    "    text = text.strip()\n",
    "    text = text + \" \"\n",
    "\n",
    "    # Format IDs with leading zeros\n",
    "    chapter_id_str = str(chapter_id).zfill(3)\n",
    "    section_id_str = str(section_id).zfill(3)\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(f\"books/{book_id}/kokoro_audio\", exist_ok=True)\n",
    "\n",
    "    # Generate audio with Kokoro TTS\n",
    "    generator = pipeline(text, voice='af_heart', speed=1)\n",
    "\n",
    "    # Process each sentence\n",
    "    for i, (gs, ps, audio) in enumerate(generator):\n",
    "        # Create a unique sentence ID\n",
    "        sentence_id = str(i).zfill(3)\n",
    "\n",
    "        # Create filename\n",
    "        filename = f\"books/{book_id}/kokoro_audio/gutenberg_{book_id}_{chapter_id_str}_{section_id_str}_{sentence_id}.wav\"\n",
    "\n",
    "        # Save the audio file\n",
    "        sf.write(filename, audio, 24000)\n",
    "\n",
    "    print(f\"Generated audio for chapter {chapter_id}, section {section_id}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# Process each cleaned text file with Kokoro TTS\n",
    "def process_cleaned_files_with_kokoro(book_id, chapter_start, chapter_stop):\n",
    "    \"\"\"Process all cleaned text files within the specified chapter range with Kokoro TTS.\"\"\"\n",
    "    print(f\"Processing chapters {chapter_start} to {chapter_stop} with Kokoro TTS\")\n",
    "\n",
    "    # Get all available text files\n",
    "    txt_dir = f\"books/{book_id}/txt\"\n",
    "\n",
    "    processed_files = 0\n",
    "    for chapter_id in range(chapter_start, chapter_stop + 1):\n",
    "        # Find all section files for this chapter\n",
    "        section_files = [f for f in os.listdir(txt_dir)\n",
    "                         if f.startswith(f\"clean_text_{chapter_id:03d}_\") and f.endswith(\".txt\")]\n",
    "\n",
    "        if not section_files:\n",
    "            print(f\"No sections found for chapter {chapter_id}\")\n",
    "            continue\n",
    "\n",
    "        section_files.sort()\n",
    "        print(f\"Found {len(section_files)} sections for chapter {chapter_id}\")\n",
    "\n",
    "        # Process each section\n",
    "        for section_file in section_files:\n",
    "            # Extract section ID from filename\n",
    "            section_id = int(section_file.split('_')[3].split('.')[0])\n",
    "\n",
    "            # Load the section text\n",
    "            with open(os.path.join(txt_dir, section_file), \"r\") as f:\n",
    "                section_text = f.read()\n",
    "\n",
    "            print(f\"Processing chapter {chapter_id}, section {section_id}\")\n",
    "            result = text_to_wav_kokoro(\n",
    "                pipeline=pipeline,\n",
    "                text=section_text,\n",
    "                book_id=book_id,\n",
    "                chapter_id=chapter_id,\n",
    "                section_id=section_id\n",
    "            )\n",
    "\n",
    "            if result:\n",
    "                processed_files += 1\n",
    "\n",
    "    print(f\"Finished processing {processed_files} sections across chapters {chapter_start} to {chapter_stop}\")\n",
    "\n",
    "\n",
    "# Run the processing\n",
    "process_cleaned_files_with_kokoro(BOOK_ID, CHAPTER_START, CHAPTER_STOP)\n",
    "\n",
    "# Combine all wav files for each chapter into one mp3 file\n",
    "from pydub import AudioSegment\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def concatenate_wav_to_chapters(book_id, add_silence_ms=1500):\n",
    "    \"\"\"\n",
    "    Concatenate all WAV files for each chapter into a single MP3 file.\n",
    "    Add specified amount of silence at the end of each chapter.\n",
    "    \"\"\"\n",
    "    # Create output directory for concatenated chapters\n",
    "    output_dir = f\"books/{book_id}/chapters\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Get all WAV files in the audio directory\n",
    "    audio_dir = f\"books/{book_id}/kokoro_audio\"\n",
    "    if not os.path.exists(audio_dir):\n",
    "        print(f\"Audio directory {audio_dir} not found\")\n",
    "        return\n",
    "\n",
    "    # Group files by chapter and section\n",
    "    chapter_files = {}\n",
    "    for file_path in glob.glob(f\"{audio_dir}/gutenberg_{book_id}_*.wav\"):\n",
    "        # Extract chapter and section IDs from filename\n",
    "        filename = os.path.basename(file_path)\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 5:\n",
    "            chapter_id = parts[2]\n",
    "            section_id = parts[3]\n",
    "            sentence_id = parts[4].split('.')[0]\n",
    "\n",
    "            if chapter_id not in chapter_files:\n",
    "                chapter_files[chapter_id] = {}\n",
    "\n",
    "            if section_id not in chapter_files[chapter_id]:\n",
    "                chapter_files[chapter_id][section_id] = []\n",
    "\n",
    "            chapter_files[chapter_id][section_id].append((file_path, int(sentence_id)))\n",
    "\n",
    "    # Process each chapter\n",
    "    for chapter_id in sorted(chapter_files.keys()):\n",
    "        print(f\"Processing chapter {chapter_id}\")\n",
    "\n",
    "        # Concatenate all sections for this chapter\n",
    "        combined = AudioSegment.empty()\n",
    "\n",
    "        # Add silence between sentences and sections\n",
    "        sentence_pause = AudioSegment.silent(duration=300)\n",
    "        section_pause = AudioSegment.silent(duration=800)\n",
    "\n",
    "        # Process each section in order\n",
    "        for section_id in sorted(chapter_files[chapter_id].keys()):\n",
    "            # Sort files by sentence ID\n",
    "            files = sorted(chapter_files[chapter_id][section_id], key=lambda x: x[1])\n",
    "\n",
    "            # Add section pause if not the first section\n",
    "            if combined.duration_seconds > 0:\n",
    "                combined += section_pause\n",
    "\n",
    "            # Process each sentence in the section\n",
    "            for file_path, _ in files:\n",
    "                print(f\"  Adding {os.path.basename(file_path)}\")\n",
    "                audio = AudioSegment.from_wav(file_path)\n",
    "                combined += audio\n",
    "                combined += sentence_pause\n",
    "\n",
    "        # Add silence at the end of the chapter\n",
    "        silence = AudioSegment.silent(duration=add_silence_ms)\n",
    "        combined += silence\n",
    "\n",
    "        # Export the combined audio\n",
    "        output_file = f\"{output_dir}/gutenberg_{book_id}_kokoro_chapter_{chapter_id}.mp3\"\n",
    "        combined.export(output_file, format=\"mp3\", parameters=[\"-b:a\", \"192k\", \"-ar\", \"44100\"])\n",
    "\n",
    "        print(f\"Created chapter file: {output_file} ({len(combined) / 1000:.2f} seconds)\")\n",
    "\n",
    "    print(f\"Finished concatenating {len(chapter_files)} chapters\")\n",
    "\n",
    "\n",
    "# Run the concatenation process\n",
    "concatenate_wav_to_chapters(BOOK_ID)"
   ],
   "id": "c1f605bdc1dbdcf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 cleaned text files.\n",
      "Processing chapters 0 to 99 with Kokoro TTS\n",
      "Found 1 sections for chapter 0\n",
      "Processing chapter 0, section 0\n",
      "Generated audio for chapter 0, section 0\n",
      "Found 1 sections for chapter 1\n",
      "Processing chapter 1, section 0\n",
      "Generated audio for chapter 1, section 0\n",
      "Found 6 sections for chapter 2\n",
      "Processing chapter 2, section 0\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef161cf89c35e0d8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
