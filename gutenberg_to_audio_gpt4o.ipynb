{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gutenberg to Audio with GPT-4o\n",
    "\n",
    "This notebook converts Project Gutenberg books to high-quality audiobooks using OpenAI's GPT-4o and TTS models. The process includes:\n",
    "\n",
    "1. Downloading and cleaning text from Project Gutenberg\n",
    "2. Analyzing the text for TTS-specific issues (abbreviations, formatting, etc.)\n",
    "3. Processing the text to make it suitable for text-to-speech\n",
    "4. Generating audio using OpenAI's TTS models\n",
    "5. Quality control and concatenation of audio files\n",
    "\n",
    "## Requirements\n",
    "- OpenAI API key configured in your environment\n",
    "- Python libraries: requests, os, re, json, math, openai, pydub\n",
    "- Sufficient OpenAI API credits for text processing and audio generation\n",
    "\n",
    "## Usage\n",
    "- Set the `BOOK_ID` variable to your desired Project Gutenberg book ID\n",
    "- Adjust chapter ranges with `CHAPTER_START` and `CHAPTER_STOP` variables\n",
    "- Run cells sequentially to process the book"
   ],
   "id": "349ab08ccda3445a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Download and Clean Text from Project Gutenberg\n",
    "\n",
    "This cell downloads a book from Project Gutenberg using the specified `BOOK_ID` and cleans the text for processing.\n",
    "\n",
    "The cleaning process:\n",
    "- Removes Project Gutenberg header and footer content\n",
    "- Removes footnotes, page numbers, and other non-narrative elements\n",
    "- Normalizes formatting, including dashes and whitespace\n",
    "- Processes line breaks to create a flowing text\n",
    "\n",
    "**Note:** Modify the `BOOK_ID` variable to download a different book. You can find book IDs in Project Gutenberg URLs.\n"
   ],
   "id": "610ac1749c80ef31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T05:28:14.122681Z",
     "start_time": "2025-03-21T05:28:12.076583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "\n",
    "BOOK_ID = \"46468\"\n",
    "\n",
    "# Define start and end strings for cleaning\n",
    "startstrings = (\n",
    "    '*** START OF THE PROJECT GUTENBERG EBOOK',\n",
    "    '***START OF THE PROJECT GUTENBERG EBOOK',\n",
    "    '*** START OF THIS PROJECT GUTENBERG EBOOK',\n",
    "    ' *** START OF THIS PROJECT GUTENBERG EBOOK',\n",
    "    'START OF THIS PROJECT GUTENBERG EBOOK',\n",
    "    '*** START OF PROJECT GUTENBERG EBOOK',\n",
    "    '*** START OF THE PROJECT GUTENBERG ETEXT',\n",
    "    '*END THE SMALL PRINT!',\n",
    "    '*END*THE SMALL PRINT!',\n",
    "    '**END THE SMALL PRINT!',\n",
    "    '*SMALL PRINT! Ver',\n",
    "    '**The Project Gutenberg Etext',\n",
    "    '*****These eBooks Were Prepared By Thousands of Volunteers'\n",
    ")\n",
    "\n",
    "endstrings = (\n",
    "    '*** END OF THE PROJECT GUTENBERG EBOOK',\n",
    "    '***END OF THE PROJECT GUTENBERG EBOOK',\n",
    "    'End of the Project Gutenberg EBook',\n",
    "    '*** END OF THIS PROJECT GUTENBERG EBOOK',\n",
    "    'END OF PROJECT GUTENBERG ETEXT',\n",
    "    'End of The Project Gutenberg Etext',\n",
    "    'End of the Project Gutenberg etext',\n",
    "    'End of Project Gutenberg Etext',\n",
    "    \"End of Project Gutenberg's Etext\",\n",
    "    ' *** END OF THIS PROJECT GUTENBERG EBOOK',\n",
    "    '      *** END OF THIS PROJECT GUTENBERG EBOOK',\n",
    "    '       *** END OF THIS PROJECT GUTENBERG EBOOK',\n",
    "    'End of this Etext',\n",
    "    'End of this Project Gutenberg Etext',\n",
    "    'End of the Project Gutenberg Etext',\n",
    "    'End of The Project Gutenberg EBook',\n",
    "    '*** START: FULL LICENSE ***'\n",
    ")\n",
    "\n",
    "url = f\"https://www.gutenberg.org/cache/epub/{BOOK_ID}/pg{BOOK_ID}.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Clean the text by removing content before start string and after end string\n",
    "def clean_gutenberg_text(text, startstrings, endstrings):\n",
    "    # Find the position of the start string\n",
    "    start_pos = len(text)\n",
    "    for start_str in startstrings:\n",
    "        pos = text.find(start_str)\n",
    "        if pos != -1 and pos < start_pos:\n",
    "            start_pos = pos\n",
    "\n",
    "    # Find the position of the end string\n",
    "    end_pos = -1\n",
    "    for end_str in endstrings:\n",
    "        pos = text.find(end_str)\n",
    "        if pos != -1 and (end_pos == -1 or pos > end_pos):\n",
    "            end_pos = pos\n",
    "\n",
    "    # Extract the text between start and end positions\n",
    "    if start_pos < len(text) and end_pos > start_pos:\n",
    "        # Find the end of the line containing the start string\n",
    "        start_line_end = text.find('\\n', start_pos)\n",
    "        if start_line_end != -1:\n",
    "            start_pos = start_line_end + 1\n",
    "\n",
    "        # Clean text is everything after the start string line and before the end string\n",
    "        raw_text = text[start_pos:end_pos].strip()\n",
    "\n",
    "        # Remove paragraphs starting with [digit]\n",
    "        raw_text = re.sub(r'(?m)^\\[\\d+\\].*?(?=\\n\\n|\\Z)', '', raw_text)\n",
    "\n",
    "        # Remove text in square brackets\n",
    "        raw_text = re.sub(r'\\[.*?\\]', '', raw_text, flags=re.DOTALL)\n",
    "\n",
    "        # Replace double-dashes with a single en-dash, ensuring spaces before and after\n",
    "        raw_text = re.sub(r'(\\S)--(\\S)', r'\\1 – \\2', raw_text)  # No spaces on either side\n",
    "        raw_text = re.sub(r'(\\S)--\\s', r'\\1 – ', raw_text)      # No space before, space after\n",
    "        raw_text = re.sub(r'\\s--(\\S)', r' – \\1', raw_text)      # Space before, no space after\n",
    "        raw_text = re.sub(r'\\s--\\s', r' – ', raw_text)          # Spaces on both sides\n",
    "\n",
    "        # Remove whitespace and invisible characters at the beginning and end of each line\n",
    "        # Filter out lines that contain only visible, non-alphanumeric characters\n",
    "        clean_lines = []\n",
    "        for line in raw_text.splitlines():\n",
    "            line = line.strip()\n",
    "\n",
    "            # Keep the line if:\n",
    "            # 1. It contains at least one alphanumeric character, OR\n",
    "            # 2. It's completely empty\n",
    "            # Remove the line if it contains only visible, non-alphanumeric characters\n",
    "            if re.search(r'[a-zA-Z0-9]', line) or not line:\n",
    "                clean_lines.append(line)\n",
    "            else:\n",
    "                # Check if line has only visible, non-alphanumeric characters\n",
    "                visible_special_chars_only = True\n",
    "                for char in line:\n",
    "                    if char.isalnum() or not char.isprintable():\n",
    "                        visible_special_chars_only = False\n",
    "                        break\n",
    "\n",
    "                # If the line doesn't consist only of visible special characters, keep it\n",
    "                if not visible_special_chars_only:\n",
    "                    clean_lines.append(line)\n",
    "\n",
    "        # Join lines with newlines\n",
    "        text_with_clean_lines = '\\n'.join(clean_lines)\n",
    "\n",
    "        # Process line breaks according to requirements\n",
    "        # First, normalize all line breaks to a standard form\n",
    "        normalized_text = re.sub(r'\\n{3,}', '\\n\\n\\n', text_with_clean_lines)  # Temporarily convert 3+ newlines to 3\n",
    "\n",
    "        # Replace single newlines with spaces\n",
    "        normalized_text = re.sub(r'([^\\n])\\n([^\\n])', r'\\1 \\2', normalized_text)\n",
    "\n",
    "        # Replace triple newlines with double newlines\n",
    "        normalized_text = re.sub(r'\\n\\n\\n', '\\n\\n', normalized_text)\n",
    "\n",
    "        return normalized_text\n",
    "    else:\n",
    "        # If no start or end string found, apply the same cleaning to the original text\n",
    "        # Remove paragraphs starting with [digit]\n",
    "        text = re.sub(r'(?m)^\\[\\d+\\].*?(?=\\n\\n|\\Z)', '', text)\n",
    "\n",
    "        # Remove text in square brackets\n",
    "        text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "        # Replace double-dashes with a single en-dash, ensuring spaces before and after\n",
    "        text = re.sub(r'(\\S)--(\\S)', r'\\1 – \\2', text)  # No spaces on either side\n",
    "        text = re.sub(r'(\\S)--\\s', r'\\1 – ', text)      # No space before, space after\n",
    "        text = re.sub(r'\\s--(\\S)', r' – \\1', text)      # Space before, no space after\n",
    "        text = re.sub(r'\\s--\\s', r' – ', text)          # Spaces on both sides\n",
    "\n",
    "        # add the <chapter> Tag one line before each chapter headline (Text starts with \"CHAPTER\")\n",
    "        text = text.replace(\"\\nCHAPTER\", \"<chapter>\\nCHAPTER\")\n",
    "        # remove repeating <chapter> tags (2 or more)\n",
    "        text = text.replace(\"<chapter><chapter>\", \"<chapter>\")\n",
    "        text = text.replace(\"<chapter><chapter>\", \"<chapter>\")\n",
    "        text = text.replace(\"<chapter><chapter>\", \"<chapter>\")\n",
    "\n",
    "        clean_lines = []\n",
    "        for line in text.splitlines():\n",
    "            line = line.strip()\n",
    "\n",
    "            # Same logic as above\n",
    "            if re.search(r'[a-zA-Z0-9]', line) or not line:\n",
    "                clean_lines.append(line)\n",
    "            else:\n",
    "                # Check if line has only visible, non-alphanumeric characters\n",
    "                visible_special_chars_only = True\n",
    "                for char in line:\n",
    "                    if char.isalnum() or not char.isprintable():\n",
    "                        visible_special_chars_only = False\n",
    "                        break\n",
    "\n",
    "                # If the line doesn't consist only of visible special characters, keep it\n",
    "                if not visible_special_chars_only:\n",
    "                    clean_lines.append(line)\n",
    "\n",
    "        text_with_clean_lines = '\\n'.join(clean_lines)\n",
    "\n",
    "        # Process line breaks\n",
    "        normalized_text = re.sub(r'\\n{3,}', '\\n\\n\\n', text_with_clean_lines)\n",
    "        normalized_text = re.sub(r'([^\\n])\\n([^\\n])', r'\\1 \\2', normalized_text)\n",
    "        normalized_text = re.sub(r'\\n\\n\\n', '\\n\\n', normalized_text)\n",
    "\n",
    "        return normalized_text\n",
    "\n",
    "\n",
    "# Clean the text\n",
    "cleaned_text = clean_gutenberg_text(response.text, startstrings, endstrings)\n",
    "\n",
    "# Ensure the books directory exists\n",
    "if not os.path.exists(\"books\"):\n",
    "    os.makedirs(\"books\")\n",
    "    print(\"Created 'books' directory\")\n",
    "\n",
    "# Save the text to a file in the \"books\" folder\n",
    "if not os.path.exists(f\"books/{BOOK_ID}\"):\n",
    "    os.makedirs(f\"books/{BOOK_ID}\")\n",
    "\n",
    "# Save cleaned text\n",
    "with open(f\"books/{BOOK_ID}/gutenberg_{BOOK_ID}.txt\", \"w\") as f:\n",
    "    f.write(cleaned_text)\n"
   ],
   "id": "d83eb3326d66d0ec",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analyze Text for TTS Preparation\n",
    "\n",
    "This cell uses OpenAI's o3-mini model to analyze the text and identify elements that need special handling for text-to-speech:\n",
    "\n",
    "- Abbreviations that should be spelled out\n",
    "- Outdated terms or place names that need modernization\n",
    "- Currency expressions and how they should be pronounced\n",
    "- Special formatting that needs conversion\n",
    "- Punctuation or number formatting issues\n",
    "- Outdated units of measurement\n",
    "\n",
    "The text is processed in chunks to stay within API limits, with results saved as JSON files.\n"
   ],
   "id": "176be0dae8960665"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T07:28:37.112969Z",
     "start_time": "2025-03-21T07:25:16.664190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load the cleaned text\n",
    "with open(f\"books/{BOOK_ID}/gutenberg_{BOOK_ID}.txt\", \"r\") as f:\n",
    "    cleaned_text = f.read()\n",
    "\n",
    "# Function to split text into chunks of max_size characters\n",
    "def split_text_into_chunks(text, max_size=50000):\n",
    "    # If text is shorter than max_size, return it as a single chunk\n",
    "    if len(text) <= max_size:\n",
    "        return [text]\n",
    "\n",
    "    chunks = []\n",
    "    # Find a good splitting point (at paragraph breaks if possible)\n",
    "    for i in range(0, len(text), max_size):\n",
    "        if i + max_size >= len(text):\n",
    "            chunks.append(text[i:])\n",
    "        else:\n",
    "            # Try to find a paragraph break near the max_size point\n",
    "            split_point = text.rfind('\\n\\n', i, i + max_size)\n",
    "            if split_point == -1 or split_point < i + max_size // 2:\n",
    "                # If no good paragraph break, find the nearest sentence end\n",
    "                split_point = text.rfind('. ', i, i + max_size)\n",
    "                if split_point == -1 or split_point < i + max_size // 2:\n",
    "                    # If no good sentence break either, just split at max_size\n",
    "                    split_point = i + max_size\n",
    "                else:\n",
    "                    split_point += 2  # Include the period and space\n",
    "            else:\n",
    "                split_point += 2  # Include the paragraph break\n",
    "\n",
    "            chunks.append(text[i:split_point])\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Function to get hints from o3-mini for a text chunk\n",
    "def get_tts_hints(text_chunk, client):\n",
    "    system_prompt = \"\"\"You are an expert in preparing text for text-to-speech processing.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"I want you to analyze the following text (a chapter from a book) and give me hints on how it can be made suitable for text-to-speech.\n",
    "\n",
    "Please create a list of hints that could cover the following aspects:\n",
    "1. What abbreviations appear and how should they be spelled out?\n",
    "2. What outdated terms, place names, or currencies that are probably no longer understandable today appear and how could they be translated into modern language? Only such terms should be modernized that are no longer understandable or can no longer be classified for today's readers.\n",
    "3. For currency conversions: How are they pronounced?\n",
    "4. What special formatting (e.g. tables, lists) appears and how should it be converted into readable text?\n",
    "5. Are there any peculiarities in punctuation or number formatting that could be problematic for TTS?\n",
    "6. Are there outdated units of measurement and how can they be converted into metric units?\n",
    "\n",
    "Your hints will later be used to prepare the text uniformly for text-to-speech. Only return the hints, no explanations or comments. Only give hints on aspects that are relevant in this chapter. Leave out everything that is irrelevant for this chapter. Be brief and do not give explanations or comments. Only mention the replacements that should be made.\n",
    "\n",
    "{text_chunk}\"\"\"\n",
    "\n",
    "    response_format_prompt = \"\"\"Please only respond with a one-dimensional list of hints in JSON format, without any additional text. It should only be a simple array of strings. Only consider those aspects that are relevant in this chapter. Be brief and do not give explanations or comments. Only mention the replacements that should be made. Very important: Only consider those aspects that are relevant in this chapter. All other aspects should not be mentioned.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o3-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"user\", \"content\": response_format_prompt}\n",
    "        ],\n",
    "        max_completion_tokens=20000,\n",
    "        reasoning_effort=\"high\"\n",
    "    )\n",
    "\n",
    "    # Extract the JSON response\n",
    "    try:\n",
    "        hints = json.loads(response.choices[0].message.content)\n",
    "        return hints\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not parse JSON response\")\n",
    "        print(response.choices[0].message.content)\n",
    "        return {\"hints\": []}\n",
    "\n",
    "# Process the text in chunks and save results\n",
    "def process_text_for_tts(text, book_id):\n",
    "    # Create the OpenAI client\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Split the text into chunks\n",
    "    chunks = split_text_into_chunks(text)\n",
    "    print(f\"Split text into {len(chunks)} chunks\")\n",
    "\n",
    "    # Create directory for JSON files if it doesn't exist\n",
    "    json_dir = f\"books/{book_id}/hints\"\n",
    "    if not os.path.exists(json_dir):\n",
    "        os.makedirs(json_dir)\n",
    "\n",
    "    # Process each chunk and save results\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)}\")\n",
    "        hints = get_tts_hints(chunk, client)\n",
    "\n",
    "        # Save hints to JSON file\n",
    "        with open(f\"{json_dir}/hints_{i:03d}.json\", \"w\") as f:\n",
    "            json.dump(hints, f, indent=2)\n",
    "\n",
    "        print(f\"Saved hints for chunk {i+1} to {json_dir}/hints_{i:03d}.json\")\n",
    "\n",
    "# Run the processing\n",
    "process_text_for_tts(cleaned_text, BOOK_ID)"
   ],
   "id": "ed7f5b7461d4dae7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split text into 6 chunks\n",
      "Processing chunk 1/6\n",
      "Saved hints for chunk 1 to books/46468/json/hints_000.json\n",
      "Processing chunk 2/6\n",
      "Saved hints for chunk 2 to books/46468/json/hints_001.json\n",
      "Processing chunk 3/6\n",
      "Saved hints for chunk 3 to books/46468/json/hints_002.json\n",
      "Processing chunk 4/6\n",
      "Saved hints for chunk 4 to books/46468/json/hints_003.json\n",
      "Processing chunk 5/6\n",
      "Saved hints for chunk 5 to books/46468/json/hints_004.json\n",
      "Processing chunk 6/6\n",
      "Saved hints for chunk 6 to books/46468/json/hints_005.json\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Consolidate TTS Preparation Hints\n",
    "\n",
    "This cell combines all the hints generated from individual text chunks into a single, deduplicated list.\n",
    "\n",
    "The consolidated hints will be used to guide the text-to-speech preparation process, ensuring consistent handling of abbreviations, terms, and formatting throughout the book.\n",
    "\n",
    "The final list is saved as `hints.json` in the book's directory.\n"
   ],
   "id": "112c39b6f36d5fc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T07:44:17.866086Z",
     "start_time": "2025-03-21T07:43:22.513187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def consolidate_hints(book_id):\n",
    "    \"\"\"\n",
    "    Consolidate all hints from individual JSON files into a single, deduplicated list.\n",
    "    Then ask o3-mini to summarize and organize these hints into a simple array.\n",
    "    \"\"\"\n",
    "    # Path to the JSON directory\n",
    "    json_dir = f\"books/{book_id}/hints\"\n",
    "\n",
    "    # Get all hint files\n",
    "    hint_files = [f for f in os.listdir(json_dir) if f.startswith(\"hints_\") and f.endswith(\".json\")]\n",
    "    hint_files.sort()  # Sort to process in order\n",
    "\n",
    "    # Collect all hints\n",
    "    all_hints = []\n",
    "    for file in hint_files:\n",
    "        with open(os.path.join(json_dir, file), \"r\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                # Handle different possible structures\n",
    "                if isinstance(data, list):\n",
    "                    all_hints.extend(data)\n",
    "                elif isinstance(data, dict) and \"hints\" in data:\n",
    "                    all_hints.extend(data[\"hints\"])\n",
    "                elif any(key in data for key in\n",
    "                         [\"abbreviations\", \"terms\", \"currencies\", \"formatting\", \"punctuation\", \"units\"]):\n",
    "                    # If it's a structured format, flatten it\n",
    "                    for category in data.values():\n",
    "                        if isinstance(category, list):\n",
    "                            all_hints.extend(category)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not parse JSON in {file}\")\n",
    "\n",
    "    # Remove duplicates while preserving order\n",
    "    unique_hints = []\n",
    "    for hint in all_hints:\n",
    "        if hint not in unique_hints and hint.strip():  # Skip empty hints\n",
    "            unique_hints.append(hint)\n",
    "\n",
    "    print(f\"Collected {len(all_hints)} hints, {len(unique_hints)} after deduplication\")\n",
    "\n",
    "    # Ask o3-mini to organize and summarize the hints\n",
    "    client = OpenAI()\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert in preparing text for text-to-speech processing.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"I have collected the following hints for text-to-speech preparation from different parts of a book:\n",
    "\n",
    "{json.dumps(unique_hints, indent=2)}\n",
    "\n",
    "Please consolidate these hints into a comprehensive, non-redundant list of replacements that apply to the entire book.\n",
    "\n",
    "Important requirements:\n",
    "1. Only include replacements that should be applied throughout the entire book\n",
    "2. Do NOT include spelling corrections. Do not replace dashes (–) or apostrophes.\n",
    "3. Focus only on:\n",
    "   - Abbreviations and how they should be spelled out\n",
    "   - Outdated terms/place names/currencies and their modern equivalents\n",
    "   - How currencies should be pronounced\n",
    "   - Special formatting instructions\n",
    "   - Punctuation or number formatting issues\n",
    "   - Outdated units of measurement and their metric conversions\n",
    "\n",
    "Each hint should be a clear instruction for replacement, like \"Replace 'Dr.' with 'Doctor'\" or \"Convert '£5' to 'five pounds'\".\n",
    "\"\"\"\n",
    "\n",
    "    response_format_prompt = \"\"\"Please respond ONLY with a one-dimensional array (simple list) of strings in JSON format.\n",
    "Do NOT use an associative array or object with categories.\n",
    "The response should be a flat list like:\n",
    "[\"Replace 'Dr.' with 'Doctor'\", \"Replace 'Mr.' with 'Mister'\", ...]\n",
    "\n",
    "Very important: Do not include any explanations or comments outside the JSON array. The response must be valid JSON that can be parsed directly.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o3-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"user\", \"content\": response_format_prompt}\n",
    "        ],\n",
    "        max_completion_tokens=20000,\n",
    "        reasoning_effort=\"high\"\n",
    "    )\n",
    "\n",
    "    # Extract and save the consolidated hints\n",
    "    try:\n",
    "        consolidated_hints = json.loads(response.choices[0].message.content)\n",
    "\n",
    "        # Verify it's a simple list\n",
    "        if not isinstance(consolidated_hints, list):\n",
    "            print(\"Warning: Response is not a simple list. Converting to list format.\")\n",
    "            # If it's not a list, try to extract a list from it\n",
    "            if isinstance(consolidated_hints, dict):\n",
    "                temp_list = []\n",
    "                for category in consolidated_hints.values():\n",
    "                    if isinstance(category, list):\n",
    "                        temp_list.extend(category)\n",
    "                consolidated_hints = temp_list\n",
    "            else:\n",
    "                consolidated_hints = [str(consolidated_hints)]\n",
    "\n",
    "        # Save consolidated hints\n",
    "        with open(f\"{json_dir}/hints.json\", \"w\") as f:\n",
    "            json.dump(consolidated_hints, f, indent=2)\n",
    "\n",
    "        print(f\"Saved consolidated hints to {json_dir}/hints.json\")\n",
    "        return consolidated_hints\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Could not parse JSON response\")\n",
    "        print(response.choices[0].message.content)\n",
    "        return {\"error\": \"Failed to consolidate hints\"}\n",
    "\n",
    "\n",
    "# Run the consolidation after processing all chunks\n",
    "consolidated_hints = consolidate_hints(BOOK_ID)\n"
   ],
   "id": "963760674dab736e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 56 hints, 56 after deduplication\n",
      "Saved consolidated hints to books/46468/hints/hints.json\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Manual Text Preparation (Required)\n",
    "\n",
    "**IMPORTANT:** Before running the text processing cells, you must manually edit the cleaned Gutenberg text file to:\n",
    "\n",
    "1. **Remove irrelevant content:**\n",
    "   - This only requires rough cleaning at the beginning and end of the document\n",
    "   - Focus on obvious text blocks that shouldn't be read aloud\n",
    "   - Table of contents\n",
    "   - Publishing information\n",
    "   - Appendices\n",
    "   - Indexes\n",
    "   - Any other non-narrative content at the beginning or end\n",
    "\n",
    "\n",
    "2. **Insert chapter markers:**\n",
    "   - Add `<chapter>` tags on a line by themselves immediately before each chapter heading (if not already present)\n",
    "   - Example:\n",
    "     ```\n",
    "     <chapter>\n",
    "     CHAPTER I. The Beginning\n",
    "\n",
    "     It was a dark and stormy night...\n",
    "     ```\n",
    "   - Do NOT place a `<chapter>` tag at the very beginning or end of the document\n",
    "   - Only place tags between actual chapters\n",
    "\n",
    "This manual step typically takes about 5 minutes and is necessary because:\n",
    "1. Large books cannot be processed by language models in their entirety\n",
    "2. Automated detection of chapter boundaries is unreliable across different book formats\n",
    "3. Non-narrative content can negatively affect the audio quality and listening experience\n",
    "\n",
    "**What NOT to manually edit** (these will be handled automatically):\n",
    "- Footnotes and endnotes\n",
    "- Abbreviations (e.g., \"Dr.\", \"Mr.\", etc.)\n",
    "- Numbers that need to be spelled out\n",
    "- Formatting issues like dashes or quotation marks\n",
    "- Special characters or symbols\n",
    "- Currency expressions\n",
    "\n",
    "The file to edit is located at: `books/{BOOK_ID}/gutenberg_{BOOK_ID}.txt`\n"
   ],
   "id": "9c5f7f9e2a8a242f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Process Text for Text-to-Speech\n",
    "\n",
    "This cell applies the consolidated hints to prepare the text for text-to-speech conversion.\n",
    "\n",
    "The process:\n",
    "1. Splits the book into chapters and sections\n",
    "2. Processes each section with o3-mini to:\n",
    "   - Spell out abbreviations\n",
    "   - Convert numbers to words\n",
    "   - Apply specific replacements from the hints\n",
    "   - Remove elements unsuitable for reading aloud\n",
    "\n",
    "You can control which chapters to process by modifying `CHAPTER_START` and `CHAPTER_STOP` variables.\n",
    "\n",
    "Processed text is saved in the `books/{BOOK_ID}/txt/` directory.\n"
   ],
   "id": "804af03c90ea07b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T03:03:55.687682Z",
     "start_time": "2025-03-22T02:33:47.154166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "CHAPTER_START = 0\n",
    "CHAPTER_STOP = 99\n",
    "\n",
    "# Load the cleaned text\n",
    "with open(f\"books/{BOOK_ID}/gutenberg_{BOOK_ID}.txt\", \"r\") as f:\n",
    "    cleaned_text = f.read()\n",
    "\n",
    "# Load the consolidated hints\n",
    "with open(f\"books/{BOOK_ID}/hints/hints.json\", \"r\") as f:\n",
    "    import json\n",
    "\n",
    "    hints = json.load(f)\n",
    "\n",
    "\n",
    "# Function to split text into chapters based on <chapter> tags\n",
    "def split_into_chapters(text):\n",
    "    # Split by <chapter> tag\n",
    "    chapters = re.split(r'<chapter>', text)\n",
    "    # Remove empty chapters\n",
    "    chapters = [chapter.strip() for chapter in chapters if chapter.strip()]\n",
    "    return chapters\n",
    "\n",
    "\n",
    "# Function to split chapter into sections of max 3500 characters\n",
    "def split_chapter_into_sections(chapter_text, max_chars=3500):\n",
    "    sections = []\n",
    "    paragraphs = chapter_text.split('\\n\\n')\n",
    "    current_section = \"\"\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        # If adding this paragraph would exceed the limit, save current section and start a new one\n",
    "        if len(current_section + paragraph) > max_chars and current_section:\n",
    "            sections.append(current_section.strip())\n",
    "            current_section = paragraph + \"\\n\\n\"\n",
    "        else:\n",
    "            current_section += paragraph + \"\\n\\n\"\n",
    "\n",
    "    # Add the last section if it's not empty\n",
    "    if current_section.strip():\n",
    "        sections.append(current_section.strip())\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "# Function to process a section with o3-mini\n",
    "def process_section_with_o3mini(section_text, hints, client):\n",
    "    # Create a string with all the hints\n",
    "    hints_text = \"\\n\".join(hints)\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert in preparing text for text-to-speech processing. Your task is to convert text to be suitable for reading aloud. Return ONLY the converted text without any comments, explanations, or additional formatting.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"I want you to convert the following text (a chapter from a book) so that it is suitable for text-to-speech.\n",
    "It should be able to be read aloud unambiguously and no longer contain abbreviations.\n",
    "So it should be a readable text flow. All numbers should be converted to words. All abbreviations should be spelled out. If there is a year like 1995, it should be converted to 'nineteen ninety-five'.\n",
    "\n",
    "Additionally, please remove any elements that are not suitable for reading aloud, such as:\n",
    "- Footnotes and endnotes\n",
    "- Page numbers\n",
    "- Bibliographic references\n",
    "- Table of contents entries\n",
    "- Image captions or figure references\n",
    "- Any metadata or formatting instructions\n",
    "- Special characters or symbols that are not commonly used in written text. For example Markdown syntax or HTML tags.\n",
    "\n",
    "Please apply the following specific replacements and guidelines:\n",
    "{hints_text}\n",
    "\n",
    "Here is the text to convert:\n",
    "{section_text}\"\"\"\n",
    "\n",
    "    response_format_prompt = \"\"\"IMPORTANT: Please respond ONLY with the converted text itself. Do not include any explanations, comments, or formatting instructions. Do not wrap the text in quotes or code blocks. Just return the plain converted text that could be read aloud.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o3-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"user\", \"content\": response_format_prompt}\n",
    "        ],\n",
    "        max_completion_tokens=20000,\n",
    "        reasoning_effort=\"high\"\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Main processing function\n",
    "def process_book_for_tts(book_id, cleaned_text, hints, chapter_start=0, chapter_stop=99):\n",
    "    # Create OpenAI client\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Create directory for processed sections\n",
    "    output_dir = f\"books/{book_id}/txt\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Split text into chapters\n",
    "    all_chapters = split_into_chapters(cleaned_text)\n",
    "    print(f\"Found {len(all_chapters)} chapters in total\")\n",
    "\n",
    "    # Filter chapters based on start and stop indices\n",
    "    chapter_stop = min(chapter_stop, len(all_chapters) - 1)  # Ensure chapter_stop doesn't exceed available chapters\n",
    "    chapters_to_process = all_chapters[chapter_start:chapter_stop + 1]  # +1 because we want to include chapter_stop\n",
    "\n",
    "    print(f\"Processing chapters {chapter_start} to {chapter_stop} ({len(chapters_to_process)} chapters)\")\n",
    "\n",
    "    # Process each chapter\n",
    "    for relative_idx, chapter in enumerate(chapters_to_process):\n",
    "        chapter_idx = chapter_start + relative_idx\n",
    "        print(f\"Processing chapter {chapter_idx} ({relative_idx+1}/{len(chapters_to_process)})\")\n",
    "\n",
    "        # Split chapter into sections\n",
    "        sections = split_chapter_into_sections(chapter)\n",
    "        print(f\"  Split chapter {chapter_idx} into {len(sections)} sections\")\n",
    "\n",
    "        # Process each section\n",
    "        for section_idx, section in enumerate(sections):\n",
    "            print(f\"  Processing section {section_idx + 1}/{len(sections)} of chapter {chapter_idx}\")\n",
    "\n",
    "            # Process section with o3-mini\n",
    "            processed_section = process_section_with_o3mini(section, hints, client)\n",
    "\n",
    "            # Save processed section as plain text\n",
    "            output_file = f\"{output_dir}/clean_text_{chapter_idx:03d}_{section_idx:03d}.txt\"\n",
    "            with open(output_file, \"w\") as f:\n",
    "                f.write(processed_section)\n",
    "\n",
    "            print(f\"  Saved processed section to {output_file}\")\n",
    "\n",
    "\n",
    "# Run the processing\n",
    "process_book_for_tts(BOOK_ID, cleaned_text, hints, CHAPTER_START, CHAPTER_STOP)\n"
   ],
   "id": "6fa67132e2bc4649",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 chapters in total\n",
      "Processing chapters 9 to 12 (4 chapters)\n",
      "Processing chapter 9 (1/4)\n",
      "  Split chapter 10 into 8 sections\n",
      "  Processing section 1/8 of chapter 10\n",
      "  Saved processed section to books/46468/txt/clean_text_009_000.txt\n",
      "  Processing section 2/8 of chapter 10\n",
      "  Saved processed section to books/46468/txt/clean_text_009_001.txt\n",
      "  Processing section 3/8 of chapter 10\n",
      "  Saved processed section to books/46468/txt/clean_text_009_002.txt\n",
      "  Processing section 4/8 of chapter 10\n",
      "  Saved processed section to books/46468/txt/clean_text_009_003.txt\n",
      "  Processing section 5/8 of chapter 10\n",
      "  Saved processed section to books/46468/txt/clean_text_009_004.txt\n",
      "  Processing section 6/8 of chapter 10\n",
      "  Saved processed section to books/46468/txt/clean_text_009_005.txt\n",
      "  Processing section 7/8 of chapter 10\n",
      "  Saved processed section to books/46468/txt/clean_text_009_006.txt\n",
      "  Processing section 8/8 of chapter 10\n",
      "  Saved processed section to books/46468/txt/clean_text_009_007.txt\n",
      "Processing chapter 10 (2/4)\n",
      "  Split chapter 11 into 4 sections\n",
      "  Processing section 1/4 of chapter 11\n",
      "  Saved processed section to books/46468/txt/clean_text_010_000.txt\n",
      "  Processing section 2/4 of chapter 11\n",
      "  Saved processed section to books/46468/txt/clean_text_010_001.txt\n",
      "  Processing section 3/4 of chapter 11\n",
      "  Saved processed section to books/46468/txt/clean_text_010_002.txt\n",
      "  Processing section 4/4 of chapter 11\n",
      "  Saved processed section to books/46468/txt/clean_text_010_003.txt\n",
      "Processing chapter 11 (3/4)\n",
      "  Split chapter 12 into 11 sections\n",
      "  Processing section 1/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_000.txt\n",
      "  Processing section 2/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_001.txt\n",
      "  Processing section 3/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_002.txt\n",
      "  Processing section 4/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_003.txt\n",
      "  Processing section 5/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_004.txt\n",
      "  Processing section 6/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_005.txt\n",
      "  Processing section 7/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_006.txt\n",
      "  Processing section 8/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_007.txt\n",
      "  Processing section 9/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_008.txt\n",
      "  Processing section 10/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_009.txt\n",
      "  Processing section 11/11 of chapter 12\n",
      "  Saved processed section to books/46468/txt/clean_text_011_010.txt\n",
      "Processing chapter 12 (4/4)\n",
      "  Split chapter 13 into 3 sections\n",
      "  Processing section 1/3 of chapter 13\n",
      "  Saved processed section to books/46468/txt/clean_text_012_000.txt\n",
      "  Processing section 2/3 of chapter 13\n",
      "  Saved processed section to books/46468/txt/clean_text_012_001.txt\n",
      "  Processing section 3/3 of chapter 13\n",
      "  Saved processed section to books/46468/txt/clean_text_012_002.txt\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generate Narration Style Guidelines\n",
    "\n",
    "This cell analyzes a sample of the processed text to generate narration style guidelines for the text-to-speech system.\n",
    "\n",
    "The guidelines cover:\n",
    "- Tone: Overall vocal quality\n",
    "- Pacing: Reading speed and variations\n",
    "- Pronunciation: Specific enunciation guidance\n",
    "- Emotion: Emotional qualities to convey\n",
    "- Inflection: Pitch, emphasis, and vocal variation\n",
    "- Word Choice: Vocabulary considerations\n",
    "\n",
    "These guidelines help the TTS system produce more natural and appropriate narration for the book's style and content."
   ],
   "id": "4e8491c40feb369d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T09:04:51.618312Z",
     "start_time": "2025-03-21T09:04:38.026605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def generate_reader_hints(book_id):\n",
    "    # Create OpenAI client\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Create txt directory if it doesn't exist\n",
    "    output_dir = f\"books/{book_id}/txt\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Find all processed text files\n",
    "    txt_files = [f for f in os.listdir(output_dir) if f.startswith(\"clean_text_\") and f.endswith(\".txt\")]\n",
    "    txt_files.sort()\n",
    "\n",
    "    # Determine a middle chapter\n",
    "    if not txt_files:\n",
    "        print(\"No processed text files found. Please process chapters first.\")\n",
    "        return\n",
    "\n",
    "    # Extract chapter numbers from filenames\n",
    "    chapter_numbers = sorted(list(set([int(f.split('_')[2]) for f in txt_files])))\n",
    "\n",
    "    if not chapter_numbers:\n",
    "        print(\"Could not determine chapter numbers from filenames.\")\n",
    "        return\n",
    "\n",
    "    # Select a middle chapter\n",
    "    middle_chapter = chapter_numbers[len(chapter_numbers) // 2]\n",
    "    print(f\"Selected middle chapter: {middle_chapter}\")\n",
    "\n",
    "    # Find the first section of the middle chapter\n",
    "    first_section_file = None\n",
    "    for f in txt_files:\n",
    "        if f.startswith(f\"clean_text_{middle_chapter:03d}_000\"):\n",
    "            first_section_file = f\n",
    "            break\n",
    "\n",
    "    if not first_section_file:\n",
    "        # Try to find any section from the middle chapter\n",
    "        for f in txt_files:\n",
    "            if f.startswith(f\"clean_text_{middle_chapter:03d}_\"):\n",
    "                first_section_file = f\n",
    "                break\n",
    "\n",
    "    if not first_section_file:\n",
    "        print(f\"No sections found for chapter {middle_chapter}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Using file: {first_section_file}\")\n",
    "\n",
    "    # Load the text from the file\n",
    "    with open(os.path.join(output_dir, first_section_file), \"r\") as f:\n",
    "        section_text = f.read()\n",
    "\n",
    "    # Create prompt for o3-mini\n",
    "    system_prompt = \"\"\"You are an expert in providing guidance for audiobook narrators. Your task is to analyze a text sample and provide specific, detailed instructions for how it should be read aloud.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Please analyze the following text sample from a book and provide detailed guidance for a narrator who will be reading this aloud to an educated adult audience.\n",
    "\n",
    "Your guidance should cover the following aspects:\n",
    "1. Tone: The overall vocal quality and character that should be used\n",
    "2. Pacing: How quickly or slowly the text should be read, including any variations\n",
    "3. Pronunciation: Any specific guidance on how words should be enunciated\n",
    "4. Emotion: The emotional quality that should be conveyed\n",
    "5. Inflection: Guidance on pitch, emphasis, and vocal variation\n",
    "6. Word Choice: Any specific vocabulary considerations\n",
    "\n",
    "Please be specific and detailed in your guidance, tailoring it to the style and content of the text. Think about what would appeal to an educated adult audience.\n",
    "\n",
    "Here is the text sample:\n",
    "{section_text}\"\"\"\n",
    "\n",
    "    response_format_prompt = \"\"\"Format your response as follows:\n",
    "\n",
    "Tone: [detailed description]\n",
    "\n",
    "Pacing: [detailed description]\n",
    "\n",
    "Pronunciation: [detailed description]\n",
    "\n",
    "Emotion: [detailed description]\n",
    "\n",
    "Inflection: [detailed description]\n",
    "\n",
    "Word Choice: [detailed description]\n",
    "\n",
    "IMPORTANT: Provide only these six sections with their descriptions. Do not include any additional comments, explanations, or introductory text.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o3-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"user\", \"content\": response_format_prompt}\n",
    "        ],\n",
    "        max_completion_tokens=20000,\n",
    "        reasoning_effort=\"high\"\n",
    "    )\n",
    "\n",
    "    reader_hints = response.choices[0].message.content\n",
    "\n",
    "    # Save the reader hints\n",
    "    with open(f\"{output_dir}/reader_hints.txt\", \"w\") as f:\n",
    "        f.write(reader_hints)\n",
    "\n",
    "    print(f\"Saved reader hints to {output_dir}/reader_hints.txt\")\n",
    "    return reader_hints\n",
    "\n",
    "\n",
    "# Generate reader hints\n",
    "reader_hints = generate_reader_hints(BOOK_ID)\n",
    "print(\"\\nReader Hints Preview:\")\n",
    "print(\"---------------------\")\n",
    "print(reader_hints[:500] + \"...\" if len(reader_hints) > 500 else reader_hints)\n"
   ],
   "id": "517c6a4d8359e1c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected middle chapter: 4\n",
      "Using file: clean_text_004_000.txt\n",
      "Saved reader hints to books/46468/txt/reader_hints.txt\n",
      "\n",
      "Reader Hints Preview:\n",
      "---------------------\n",
      "Tone: Adopt a clear, authoritative tone with a measured formality that conveys the historical weight and vivid detail of the narrative. The overall quality should be confident and slightly reserved, inviting the listener into an account of exploration and cultural encounter without losing the narrative’s inherent warmth.\n",
      "\n",
      "Pacing: Read the text at a moderate pace that allows the listener to absorb the intricate descriptions and historical nuances. Slow down during passages that describe detailed ...\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generate Audio with OpenAI TTS\n",
    "\n",
    "This cell converts the processed text to speech using OpenAI's TTS models.\n",
    "\n",
    "Features:\n",
    "- Uses the reader hints to guide the narration style\n",
    "- Processes each section separately\n",
    "- Supports different voice options (default: \"coral\")\n",
    "- Works with both standard TTS models and GPT-4o-mini-TTS\n",
    "\n",
    "You can control which chapters to process by modifying `CHAPTER_START` and `CHAPTER_STOP` variables.\n",
    "\n",
    "Audio files are saved in the `books/{BOOK_ID}/audio/` directory.\n"
   ],
   "id": "f6dc6a2c26ba5366"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:43:00.851890Z",
     "start_time": "2025-03-22T11:43:00.761766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configuration variables\n",
    "BOOK_ID = \"46468\"\n",
    "CHAPTER_START = 0\n",
    "CHAPTER_STOP = 99\n",
    "# Available voices: alloy, ash, coral, echo, fable, onyx, nova, sage, shimmer\n",
    "VOICE_NAME = \"coral\"  # Default voice\n",
    "\n",
    "def text_to_wav_openai_tts(text: str, book_id: str, chapter_id: int, section_id: int,\n",
    "                           voice_name: str, model: str = \"gpt-4o-mini-tts\",\n",
    "                           instructions: str = None, speed: float = 1.0, response_format: str = \"mp3\") -> str:\n",
    "    \"\"\"Convert text to speech using OpenAI TTS and save as an audio file.\"\"\"\n",
    "    # Remove line breaks and whitespace from the beginning and end of the text\n",
    "    text = text.strip()\n",
    "    text = text + \" \"\n",
    "\n",
    "    # Check text length (max 4096 characters)\n",
    "    if len(text) > 4096:\n",
    "        print(f\"Warning: Text is too long ({len(text)} characters). Truncating to 4096 characters.\")\n",
    "        text = text[:4093] + \"...\"\n",
    "\n",
    "    # Check speed (between 0.25 and 4.0)\n",
    "    if speed < 0.25 or speed > 4.0:\n",
    "        print(f\"Warning: Invalid speed {speed}. Setting to 1.0.\")\n",
    "        speed = 1.0\n",
    "\n",
    "    # Initialize OpenAI Client\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Format IDs with leading zeros\n",
    "    chapter_id_str = str(chapter_id).zfill(3)\n",
    "    section_id_str = str(section_id).zfill(3)\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(f\"books/{book_id}/audio\", exist_ok=True)\n",
    "\n",
    "    # Generate audio with OpenAI TTS\n",
    "    try:\n",
    "        # Create filename with audio format\n",
    "        file_extension = response_format if response_format != \"pcm\" else \"wav\"\n",
    "        filename = f\"books/{book_id}/audio/gutenberg_{book_id}_{chapter_id_str}_{section_id_str}.{file_extension}\"\n",
    "\n",
    "        # Create parameters for the API\n",
    "        params = {\n",
    "            \"model\": model,\n",
    "            \"voice\": voice_name,\n",
    "            \"input\": text,\n",
    "            \"response_format\": response_format,\n",
    "            \"speed\": speed\n",
    "        }\n",
    "\n",
    "        # Add instructions if available and the model is not tts-1 or tts-1-hd\n",
    "        if instructions and model not in [\"tts-1\", \"tts-1-hd\"]:\n",
    "            params[\"instructions\"] = instructions\n",
    "\n",
    "        # Call the API\n",
    "        with client.audio.speech.with_streaming_response.create(**params) as response:\n",
    "            # Open the file in binary write mode\n",
    "            with open(filename, 'wb') as f:\n",
    "                # Write the response content to the file\n",
    "                for chunk in response.iter_bytes():\n",
    "                    f.write(chunk)\n",
    "\n",
    "        return filename\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating audio with OpenAI TTS: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Load reader hints\n",
    "reader_hints_file = f\"books/{BOOK_ID}/txt/reader_hints.txt\"\n",
    "if os.path.exists(reader_hints_file):\n",
    "    with open(reader_hints_file, \"r\") as f:\n",
    "        reader_hints = f.read()\n",
    "    print(\"Loaded reader hints for TTS instructions\")\n",
    "else:\n",
    "    reader_hints = \"\"\n",
    "    print(\"No reader hints found, will use default TTS settings\")\n",
    "\n",
    "\n",
    "# Function to process a section with TTS\n",
    "def process_section_with_tts(book_id, chapter_id, section_id, voice_name=VOICE_NAME, model=\"gpt-4o-mini-tts\"):\n",
    "    # Load the section text\n",
    "    section_file = f\"books/{book_id}/txt/clean_text_{chapter_id:03d}_{section_id:03d}.txt\"\n",
    "\n",
    "    if not os.path.exists(section_file):\n",
    "        print(f\"Section file {section_file} not found\")\n",
    "        return\n",
    "\n",
    "    with open(section_file, \"r\") as f:\n",
    "        section_text = f.read()\n",
    "\n",
    "    print(f\"Processing section from chapter {chapter_id}, section {section_id}\")\n",
    "\n",
    "    # Generate audio for the entire section\n",
    "    filename = text_to_wav_openai_tts(\n",
    "        text=section_text,\n",
    "        book_id=book_id,\n",
    "        chapter_id=chapter_id,\n",
    "        section_id=section_id,\n",
    "        voice_name=voice_name,\n",
    "        model=model,\n",
    "        instructions=reader_hints if model == \"gpt-4o-mini-tts\" else None\n",
    "    )\n",
    "\n",
    "    if filename:\n",
    "        print(f\"Generated audio: {filename}\")\n",
    "        return filename\n",
    "    else:\n",
    "        print(f\"Failed to generate audio for chapter {chapter_id}, section {section_id}\")\n",
    "        return None\n",
    "\n",
    "def process_chapters_with_tts(book_id, chapter_start, chapter_stop, voice_name=VOICE_NAME, model=\"gpt-4o-mini-tts\"):\n",
    "    \"\"\"Process all chapters within the specified range with TTS.\"\"\"\n",
    "    print(f\"Processing chapters {chapter_start} to {chapter_stop} with TTS using voice: {voice_name}\")\n",
    "\n",
    "    # Get all available text files\n",
    "    txt_dir = f\"books/{book_id}/txt\"\n",
    "    if not os.path.exists(txt_dir):\n",
    "        print(f\"Text directory {txt_dir} not found\")\n",
    "        return\n",
    "\n",
    "    # Find all chapter files within the range\n",
    "    processed_files = 0\n",
    "    for chapter_id in range(chapter_start, chapter_stop + 1):\n",
    "        # Find all section files for this chapter\n",
    "        section_files = [f for f in os.listdir(txt_dir)\n",
    "                         if f.startswith(f\"clean_text_{chapter_id:03d}_\") and f.endswith(\".txt\")]\n",
    "\n",
    "        if not section_files:\n",
    "            print(f\"No sections found for chapter {chapter_id}\")\n",
    "            continue\n",
    "\n",
    "        section_files.sort()\n",
    "        print(f\"Found {len(section_files)} sections for chapter {chapter_id}\")\n",
    "\n",
    "        # Process each section\n",
    "        for section_file in section_files:\n",
    "            # Extract section ID from filename\n",
    "            section_id = int(section_file.split('_')[3].split('.')[0])\n",
    "\n",
    "            print(f\"Processing chapter {chapter_id}, section {section_id}\")\n",
    "            result = process_section_with_tts(\n",
    "                book_id=book_id,\n",
    "                chapter_id=chapter_id,\n",
    "                section_id=section_id,\n",
    "                voice_name=voice_name,\n",
    "                model=model\n",
    "            )\n",
    "\n",
    "            if result:\n",
    "                processed_files += 1\n",
    "\n",
    "    print(f\"Finished processing {processed_files} sections across chapters {chapter_start} to {chapter_stop}\")\n",
    "\n",
    "# Process chapters with the configured voice\n",
    "process_chapters_with_tts(BOOK_ID, CHAPTER_START, CHAPTER_STOP, voice_name=VOICE_NAME)\n"
   ],
   "id": "c3b56a6d53b4b8b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded reader hints for TTS instructions\n",
      "Processing chapters 0 to 1 with TTS\n",
      "Found 1 sections for chapter 0\n",
      "Processing chapter 0, section 0\n",
      "Processing section from chapter 0, section 0\n",
      "Fehler bei der Generierung von Audio mit OpenAI TTS: Speech.create() got an unexpected keyword argument 'temperature'\n",
      "Failed to generate audio for chapter 0, section 0\n",
      "Found 3 sections for chapter 1\n",
      "Processing chapter 1, section 0\n",
      "Processing section from chapter 1, section 0\n",
      "Fehler bei der Generierung von Audio mit OpenAI TTS: Speech.create() got an unexpected keyword argument 'temperature'\n",
      "Failed to generate audio for chapter 1, section 0\n",
      "Processing chapter 1, section 1\n",
      "Processing section from chapter 1, section 1\n",
      "Fehler bei der Generierung von Audio mit OpenAI TTS: Speech.create() got an unexpected keyword argument 'temperature'\n",
      "Failed to generate audio for chapter 1, section 1\n",
      "Processing chapter 1, section 2\n",
      "Processing section from chapter 1, section 2\n",
      "Fehler bei der Generierung von Audio mit OpenAI TTS: Speech.create() got an unexpected keyword argument 'temperature'\n",
      "Failed to generate audio for chapter 1, section 2\n",
      "Finished processing 0 sections across chapters 0 to 1\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Quality Control: Detect Issues in Audio Files\n",
    "\n",
    "This cell analyzes the generated audio files to identify potential quality issues:\n",
    "\n",
    "- Silent segments that might indicate processing problems\n",
    "- Length discrepancies between expected and actual duration\n",
    "- Other anomalies that could affect listening experience\n",
    "\n",
    "The analysis helps identify files that may need regeneration due to quality issues.\n"
   ],
   "id": "de6e885cedadecaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:11:10.747750Z",
     "start_time": "2025-03-22T11:09:40.288593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from audio_processing import detect_silence_in_mp3_parallel\n",
    "\n",
    "# Run the silence detection with the book ID from the notebook\n",
    "silence_results = detect_silence_in_mp3_parallel(\n",
    "    book_id=BOOK_ID,\n",
    "    silence_threshold=-50,\n",
    "    min_silence_duration=3000,\n",
    "    expected_seconds_per_1000_chars=60,\n",
    "    length_tolerance=0.4,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Found {len(silence_results)} files with issues\")\n",
    "\n",
    "# Count files with silence issues\n",
    "silence_issue_count = sum(1 for file_info in silence_results if file_info.get('has_silence_issue', False))\n",
    "print(f\"Files with silence issues: {silence_issue_count}\")\n",
    "\n",
    "# Count files with length issues\n",
    "length_issue_count = sum(1 for file_info in silence_results if file_info.get('has_length_issue', False))\n",
    "print(f\"Files with length issues: {length_issue_count}\")\n",
    "\n",
    "# Detailed report\n",
    "for file_info in silence_results:\n",
    "    print(f\"\\nChapter {file_info['chapter_id']}, Section {file_info['section_id']}:\")\n",
    "\n",
    "    # Report silence issues\n",
    "    if file_info.get('has_silence_issue', False):\n",
    "        silent_segments = file_info['silent_segments']\n",
    "        print(f\"  Silence issues: {len(silent_segments)} silent segments\")\n",
    "        # Calculate percentage of silence\n",
    "        total_silence = sum(duration for _, _, duration in silent_segments)\n",
    "        silence_percentage = (total_silence / file_info['duration']) * 100 if file_info['duration'] > 0 else 0\n",
    "        print(f\"  Total silence: {total_silence:.2f}s ({silence_percentage:.2f}% of {file_info['duration']:.2f}s total)\")\n",
    "\n",
    "    # Report length issues\n",
    "    if file_info.get('has_length_issue', False):\n",
    "        print(f\"  Length issue: Text length: {file_info.get('text_length', 'N/A')} chars\")\n",
    "        print(f\"  Expected duration: {file_info.get('expected_duration', 'N/A'):.2f}s\")\n",
    "        print(f\"  Actual duration: {file_info['duration']:.2f}s\")\n",
    "        print(f\"  Difference: {file_info.get('duration_diff_percent', 'N/A'):.2f}%\")"
   ],
   "id": "e923a7d89f0801bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 MP3 files to analyze\n",
      "Chapter 004, Section 000 contains 1 silent segments:\n",
      "  Silent from 267.43s to 271.61s (duration: 4.18s)\n",
      "Chapter 011, Section 008 contains 1 silent segments:\n",
      "  Silent from 252.88s to 256.80s (duration: 3.92s)\n",
      "\n",
      "Summary:\n",
      "Found 2 files with issues\n",
      "Files with silence issues: 2\n",
      "Files with length issues: 0\n",
      "\n",
      "Chapter 004, Section 000:\n",
      "  Silence issues: 1 silent segments\n",
      "  Total silence: 4.18s (1.54% of 271.61s total)\n",
      "\n",
      "Chapter 011, Section 008:\n",
      "  Silence issues: 1 silent segments\n",
      "  Total silence: 3.92s (1.53% of 256.80s total)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Regenerate Problematic Audio Files\n",
    "\n",
    "This cell regenerates any audio files that were identified as having issues in the previous step.\n",
    "\n",
    "The process:\n",
    "1. Identifies files with silence or length issues\n",
    "2. Regenerates those specific files using the same voice and model\n",
    "3. Re-analyzes the regenerated files to confirm issues are resolved\n",
    "\n",
    "**IMPORTANT:** Run this cell and the silence detection cell repeatedly until no more issues are found. Sometimes regenerated files may still have problems and require multiple regeneration attempts to achieve optimal quality.\n",
    "\n",
    "This ensures all audio segments meet quality standards before final assembly.\n"
   ],
   "id": "23d09ceb66827a98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:16:59.142142Z",
     "start_time": "2025-03-22T11:16:02.452703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def regenerate_files_with_issues(book_id, voice_name=VOICE_NAME, model=\"gpt-4o-mini-tts\"):\n",
    "    \"\"\"Regenerate files that have silence or length issues.\"\"\"\n",
    "\n",
    "    if not silence_results:\n",
    "        print(\"No files with issues detected. Nothing to regenerate.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nFound {len(silence_results)} files with issues. Regenerating with voice: {voice_name}\")\n",
    "\n",
    "    # Regenerate each file with issues\n",
    "    for file_info in silence_results:\n",
    "        # Convert chapter_id and section_id to integers if they're strings\n",
    "        chapter_id = int(file_info['chapter_id']) if isinstance(file_info['chapter_id'], str) else file_info['chapter_id']\n",
    "        section_id = int(file_info['section_id']) if isinstance(file_info['section_id'], str) else file_info['section_id']\n",
    "\n",
    "        print(f\"\\nRegenerating Chapter {chapter_id}, Section {section_id}\")\n",
    "\n",
    "        # Report the issues\n",
    "        if file_info.get('has_silence_issue', False):\n",
    "            print(f\"Original file had {len(file_info['silent_segments'])} silent segments\")\n",
    "\n",
    "        if file_info.get('has_length_issue', False):\n",
    "            print(f\"Original file had length issue: expected {file_info.get('expected_duration', 'N/A'):.2f}s, got {file_info['duration']:.2f}s\")\n",
    "\n",
    "        # Process this section with the new voice\n",
    "        result = process_section_with_tts(\n",
    "            book_id=book_id,\n",
    "            chapter_id=chapter_id,\n",
    "            section_id=section_id,\n",
    "            voice_name=voice_name,\n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        if result:\n",
    "            print(f\"Successfully regenerated: {result}\")\n",
    "        else:\n",
    "            print(f\"Failed to regenerate Chapter {chapter_id}, Section {section_id}\")\n",
    "\n",
    "    print(\"\\nFinished regenerating files with issues\")\n",
    "\n",
    "# Run the regeneration process\n",
    "regenerate_files_with_issues(BOOK_ID)\n",
    "\n",
    "\n",
    "# Run the silence detection with the book ID from the notebook\n",
    "silence_results = detect_silence_in_mp3_parallel(\n",
    "    book_id=BOOK_ID,\n",
    "    silence_threshold=-50,  # Adjust this threshold as needed (-50 dB is a good starting point)\n",
    "    min_silence_duration=3000,  # Minimum 3 seconds of silence (in milliseconds)\n",
    "    expected_seconds_per_1000_chars=60,  # Expect 60 seconds of audio per 1000 characters\n",
    "    length_tolerance=0.4,  # Allow 40% deviation from expected length\n",
    "    silence_results=silence_results,\n",
    "    max_workers=4  # For max_workers CPU cores\n",
    "\n",
    ")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Found {len(silence_results)} files with issues\")\n",
    "\n",
    "# Count files with silence issues\n",
    "silence_issue_count = sum(1 for file_info in silence_results if file_info.get('has_silence_issue', False))\n",
    "print(f\"Files with silence issues: {silence_issue_count}\")\n",
    "\n",
    "# Count files with length issues\n",
    "length_issue_count = sum(1 for file_info in silence_results if file_info.get('has_length_issue', False))\n",
    "print(f\"Files with length issues: {length_issue_count}\")"
   ],
   "id": "69705f21f3168f3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1 files with issues. Regenerating...\n",
      "\n",
      "Regenerating Chapter 4, Section 0\n",
      "Original file had 2 silent segments\n",
      "Original file had length issue: expected 234.12s, got 416.40s\n",
      "Processing section from chapter 4, section 0\n",
      "Generated audio: books/46468/audio/gutenberg_46468_004_000.mp3\n",
      "Successfully regenerated: books/46468/audio/gutenberg_46468_004_000.mp3\n",
      "\n",
      "Finished regenerating files with issues\n",
      "Rechecking 1 previously identified files with silence issues\n",
      "\n",
      "Summary:\n",
      "Found 0 files with issues\n",
      "Files with silence issues: 0\n",
      "Files with length issues: 0\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Assemble Final Audiobook Chapters\n",
    "\n",
    "This cell combines the individual audio section files into complete chapter files.\n",
    "\n",
    "The process:\n",
    "1. Groups audio files by chapter\n",
    "2. Sorts sections in correct order\n",
    "3. Concatenates all sections for each chapter\n",
    "4. Adds a brief silence at the end of each chapter\n",
    "5. Exports complete chapter files in MP3 format\n",
    "\n",
    "The final chapter files are saved in the `books/{BOOK_ID}/chapters/` directory, ready for listening or further processing.\n"
   ],
   "id": "8413287c49938ddf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T11:18:12.298310Z",
     "start_time": "2025-03-22T11:17:18.980684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import glob\n",
    "\n",
    "def concatenate_mp3_to_chapters(book_id, add_silence_ms=1500):\n",
    "    \"\"\"\n",
    "    Concatenate all MP3 files for each chapter into a single MP3 file.\n",
    "    Add specified amount of silence at the end of each chapter.\n",
    "\n",
    "    Args:\n",
    "        book_id (str): The ID of the book\n",
    "        add_silence_ms (int): Milliseconds of silence to add at the end of each chapter\n",
    "    \"\"\"\n",
    "    # Create output directory for concatenated chapters\n",
    "    output_dir = f\"books/{book_id}/chapters\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Get all MP3 files in the audio directory\n",
    "    audio_dir = f\"books/{book_id}/audio\"\n",
    "    if not os.path.exists(audio_dir):\n",
    "        print(f\"Audio directory {audio_dir} not found\")\n",
    "        return\n",
    "\n",
    "    # Group files by chapter\n",
    "    chapter_files = {}\n",
    "    for file_path in glob.glob(f\"{audio_dir}/gutenberg_{book_id}_*.mp3\"):\n",
    "        # Extract chapter and section IDs from filename\n",
    "        filename = os.path.basename(file_path)\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 4:\n",
    "            chapter_id = parts[2]\n",
    "            section_id = parts[3].split('.')[0]\n",
    "\n",
    "            if chapter_id not in chapter_files:\n",
    "                chapter_files[chapter_id] = []\n",
    "\n",
    "            chapter_files[chapter_id].append((file_path, int(section_id)))\n",
    "\n",
    "    # Process each chapter\n",
    "    for chapter_id, files in chapter_files.items():\n",
    "        print(f\"Processing chapter {chapter_id}\")\n",
    "\n",
    "        # Sort files by section ID\n",
    "        files.sort(key=lambda x: x[1])\n",
    "\n",
    "        # Concatenate all sections for this chapter\n",
    "        combined = AudioSegment.empty()\n",
    "        for file_path, _ in files:\n",
    "            print(f\"  Adding {os.path.basename(file_path)}\")\n",
    "            audio = AudioSegment.from_mp3(file_path)\n",
    "            combined += audio\n",
    "\n",
    "        # Add silence at the end of the chapter\n",
    "        silence = AudioSegment.silent(duration=add_silence_ms)\n",
    "        combined += silence\n",
    "\n",
    "        # Export the combined audio\n",
    "        output_file = f\"{output_dir}/chapter_{chapter_id}.mp3\"\n",
    "        combined.export(output_file, format=\"mp3\")\n",
    "\n",
    "        print(f\"Created chapter file: {output_file} ({len(combined)/1000:.2f} seconds)\")\n",
    "\n",
    "    print(f\"Finished concatenating {len(chapter_files)} chapters\")\n",
    "\n",
    "# Run the concatenation process\n",
    "concatenate_mp3_to_chapters(BOOK_ID)"
   ],
   "id": "8519227bd733d402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chapter 003\n",
      "  Adding gutenberg_46468_003_000.mp3\n",
      "  Adding gutenberg_46468_003_001.mp3\n",
      "  Adding gutenberg_46468_003_002.mp3\n",
      "  Adding gutenberg_46468_003_003.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_003.mp3 (735.44 seconds)\n",
      "Processing chapter 002\n",
      "  Adding gutenberg_46468_002_000.mp3\n",
      "  Adding gutenberg_46468_002_001.mp3\n",
      "  Adding gutenberg_46468_002_002.mp3\n",
      "  Adding gutenberg_46468_002_003.mp3\n",
      "  Adding gutenberg_46468_002_004.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_002.mp3 (1134.97 seconds)\n",
      "Processing chapter 012\n",
      "  Adding gutenberg_46468_012_000.mp3\n",
      "  Adding gutenberg_46468_012_001.mp3\n",
      "  Adding gutenberg_46468_012_002.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_012.mp3 (549.01 seconds)\n",
      "Processing chapter 011\n",
      "  Adding gutenberg_46468_011_000.mp3\n",
      "  Adding gutenberg_46468_011_001.mp3\n",
      "  Adding gutenberg_46468_011_002.mp3\n",
      "  Adding gutenberg_46468_011_003.mp3\n",
      "  Adding gutenberg_46468_011_004.mp3\n",
      "  Adding gutenberg_46468_011_005.mp3\n",
      "  Adding gutenberg_46468_011_006.mp3\n",
      "  Adding gutenberg_46468_011_007.mp3\n",
      "  Adding gutenberg_46468_011_008.mp3\n",
      "  Adding gutenberg_46468_011_009.mp3\n",
      "  Adding gutenberg_46468_011_010.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_011.mp3 (2959.45 seconds)\n",
      "Processing chapter 000\n",
      "  Adding gutenberg_46468_000_000.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_000.mp3 (13.36 seconds)\n",
      "Processing chapter 010\n",
      "  Adding gutenberg_46468_010_000.mp3\n",
      "  Adding gutenberg_46468_010_001.mp3\n",
      "  Adding gutenberg_46468_010_002.mp3\n",
      "  Adding gutenberg_46468_010_003.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_010.mp3 (970.50 seconds)\n",
      "Processing chapter 009\n",
      "  Adding gutenberg_46468_009_000.mp3\n",
      "  Adding gutenberg_46468_009_001.mp3\n",
      "  Adding gutenberg_46468_009_002.mp3\n",
      "  Adding gutenberg_46468_009_003.mp3\n",
      "  Adding gutenberg_46468_009_004.mp3\n",
      "  Adding gutenberg_46468_009_005.mp3\n",
      "  Adding gutenberg_46468_009_006.mp3\n",
      "  Adding gutenberg_46468_009_007.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_009.mp3 (1826.82 seconds)\n",
      "Processing chapter 008\n",
      "  Adding gutenberg_46468_008_000.mp3\n",
      "  Adding gutenberg_46468_008_001.mp3\n",
      "  Adding gutenberg_46468_008_002.mp3\n",
      "  Adding gutenberg_46468_008_003.mp3\n",
      "  Adding gutenberg_46468_008_004.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_008.mp3 (1126.45 seconds)\n",
      "Processing chapter 001\n",
      "  Adding gutenberg_46468_001_000.mp3\n",
      "  Adding gutenberg_46468_001_001.mp3\n",
      "  Adding gutenberg_46468_001_002.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_001.mp3 (671.20 seconds)\n",
      "Processing chapter 004\n",
      "  Adding gutenberg_46468_004_000.mp3\n",
      "  Adding gutenberg_46468_004_001.mp3\n",
      "  Adding gutenberg_46468_004_002.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_004.mp3 (608.70 seconds)\n",
      "Processing chapter 005\n",
      "  Adding gutenberg_46468_005_000.mp3\n",
      "  Adding gutenberg_46468_005_001.mp3\n",
      "  Adding gutenberg_46468_005_002.mp3\n",
      "  Adding gutenberg_46468_005_003.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_005.mp3 (858.54 seconds)\n",
      "Processing chapter 007\n",
      "  Adding gutenberg_46468_007_000.mp3\n",
      "  Adding gutenberg_46468_007_001.mp3\n",
      "  Adding gutenberg_46468_007_002.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_007.mp3 (651.95 seconds)\n",
      "Processing chapter 006\n",
      "  Adding gutenberg_46468_006_000.mp3\n",
      "  Adding gutenberg_46468_006_001.mp3\n",
      "Created chapter file: books/46468/chapters/chapter_006.mp3 (378.01 seconds)\n",
      "Finished concatenating 13 chapters\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
